# -*- coding: utf-8 -*-
"""F4F_ML.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fzVvkcBlLhj1RF60D9qQaxNfFS8SFFRi

#Machine Learning to Predict TreeDBH_cm
"""

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.linear_model import LinearRegression
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder
from sklearn.svm  import  LinearSVR
from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import GradientBoostingRegressor, AdaBoostRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.neighbors import KNeighborsRegressor
from sklearn.preprocessing import StandardScaler

df = pd.read_csv("/content/q3_data_for_assignment.xlsx - Sheet1.csv")
df.columns

"""####Data Preprocessing"""

#preprocess
processor = ColumnTransformer(
    transformers=[
        ('species',OneHotEncoder(sparse_output=False),['Tree species']),
        ('nums',StandardScaler(),['TreeHeight_foot','TreeCrown_foot'])
    ]
)

#training Datasets
df_input = df.drop('TreeDBH_cm',axis=1)
df_output = df['TreeDBH_cm']

"""####Model Setting"""

#Linear Regression
model_lr = Pipeline(
    steps=[
        ('preprocessor',processor),
        ('Linear regression',LinearRegression())
    ]
)

#Random Forest Regressor
model_rf = Pipeline(
   steps=[
        ('preprocessor',processor),
        ('Random Forest Regression',RandomForestRegressor())
    ]
)

# Support Vector Regressor
model_svr = Pipeline(steps=[
        ('preprocessor',processor),
        ('Support Vector Regressor',LinearSVR())
    ]
)

#Gradient Boosting Regressor
model_gbr = Pipeline(
    steps=[
        ('preprocessor',processor),
        ('Gradient Boosting',GradientBoostingRegressor())
        ]
)

#Adaboosting Regressor
model_abr = Pipeline(
   steps=[
        ('preprocessing',processor),
        ('Ada Boosting',AdaBoostRegressor())
    ]
)

#Decision Tree Regressor
model_dtr = Pipeline(
   steps=[
        ('preprocessor',processor),
        ('Decision Tree Regressor',DecisionTreeRegressor())
    ]
)

#KNN Regressor
model_knn = Pipeline(
    steps=[
        ('preprocessor',processor),
        ('KNN Regressor',KNeighborsRegressor())
    ]
)

"""####Data Splitting"""

X_train, X_test, y_train,y_test = train_test_split(df_input,df_output,test_size=0.2,random_state=42,shuffle=True)

"""####Training the Data in Model"""

#linear regression
model_lr.fit(X_train,y_train)

#random forest regression
model_rf.fit(X_train,y_train)

#support vector reg
model_svr.fit(X_train,y_train)

#gradient boosting reg
model_gbr.fit(X_train,y_train)

#adaboosting reg
model_abr.fit(X_train,y_train)

#Knn
model_knn.fit(X_train,y_train)

#decision tree reg
model_dtr.fit(X_train,y_train)

"""####Predict models"""

y_pred_lr = model_lr.predict(X_test)
y_pred_rf = model_rf.predict(X_test)
y_pred_svr = model_svr.predict(X_test)
y_pred_gbr = model_gbr.predict(X_test)
y_pred_abr = model_abr.predict(X_test)
y_pred_knn = model_knn.predict(X_test)
y_pred_dtr = model_dtr.predict(X_test)

"""##R2 Score"""

from sklearn.metrics import r2_score

r2_lr = r2_score(y_test,y_pred_lr)
r2_rf = r2_score(y_test,y_pred_rf)
r2_svr = r2_score(y_test,y_pred_svr)
r2_gbr = r2_score(y_test,y_pred_gbr)
r2_abr = r2_score(y_test,y_pred_abr)
r2_knn = r2_score(y_test,y_pred_knn)
r2_dtr = r2_score(y_test,y_pred_dtr)

print(f"Linear Regression {r2_lr:.3f}")
print(f"Random Forest Regression {r2_rf:.3f}")
print(f"Support Vector Regression {r2_svr:.3f}")
print(f"Gradient Boosting Regression {r2_gbr:.3f}")
print(f"Adaboosting Regression {r2_abr:.3f}")
print(f"Decision Tree Regression {r2_dtr:.3f}")
print(f"K-nearest neighbouring {r2_knn:.3f}")

"""####Example Dataset"""

ds = pd.DataFrame({
    'Tree species':['Lemon'],
    'TreeHeight_foot':[6],
    'TreeCrown_foot':[4.5]
})
print("The Original Value is: 6.687")
lr_output = model_lr.predict(ds)
print(f"Linear Regression Output: {lr_output[0]:.3f}")
rf_output = model_rf.predict(ds)
print(f"Random Forest Regression Output: {rf_output[0]:.3f}")
svr_output = model_svr.predict(ds)
print(f"Support Vector Regression Output: {svr_output[0]:.3f}")
gbr_output = model_gbr.predict(ds)
print(f"Gradient Boosting Regression Output: {gbr_output[0]:.3f}")
abr_output = model_abr.predict(ds)
print(f"Adaboosting Regression Output: {abr_output[0]:.3f}")
dtr_output = model_dtr.predict(ds)
print(f"Decision Tree Regression Output: {dtr_output[0]:.3f}")
knn_output = model_knn.predict(ds)
print(f"K-nearest neighbouring Output: {knn_output[0]:.3f}")
dtr_output = model_dtr.predict(ds)

"""#Summary

###The Original Value is 6.687, Based on the above ML model we came to know that Support Vector Regression model works well to predict TreeDBH_cm and produces same as Original Value.
"""